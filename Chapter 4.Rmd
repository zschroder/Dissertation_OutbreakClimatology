---
title: "Chapter 4"
author: "Professor Zoe Schroder"
date: "7/27/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

## Part 1: Tornado data

Load packages and suppress the messages of the packages. 
```{r}
suppressMessages(library(lubridate))
suppressMessages(library(tmap))
suppressMessages(library(USAboundaries))
suppressMessages(library(rgeos))
suppressMessages(library(dplyr))
suppressMessages(library(xts))
suppressMessages(library(raster))
suppressMessages(library(dplyr))
suppressMessages(library(ggplot2))
suppressMessages(library(lme4))
suppressMessages(library(xtable))
suppressMessages(library(ggrepel))
suppressMessages(library(viridis))
suppressMessages(library(gridExtra))
suppressMessages(library(sp))
suppressMessages(library(sf))
suppressMessages(library(lubridate))
suppressMessages(library(dplyr))
suppressMessages(library(chron))
```
Projections you may need: 
```{r}
merc <- "+proj=merc +lon_0=0 +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
US_LCC <- "+proj=lcc +lat_1=33 +lat_2=45 +lat_0=39 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m no_defs"
```

Coordinate Reference Systems you may need:
```{r, eval = FALSE}
WGS84 <- 4326
```


Use the start lon/lat and create a `sp` object then convert to `sf`. Set the coordinate reference system (crs) to ESPG to `WGS84`.
```{r, eval = FALSE}
Torn50_19.spdf <- read.csv(file = "1950-2019_actual_tornadoes.csv")
sp::coordinates(Torn50_19.spdf) <- ~ slon + slat
Torn50_19.sfdf <- st_as_sf(Torn50_19.spdf)
st_crs(Torn50_19.sfdf) <- WGS84
```

```{r, eval = FALSE}
#Torn50_18.spdf <- read.csv(file = "1950-2018_actual_tornadoes.csv")
#sp::coordinates(Torn50_18.spdf) <- ~ slon + slat
#Torn50_18.sfdf <- st_as_sf(Torn50_18.spdf)
#st_crs(Torn50_18.sfdf) <- WGS84
```

```{r, eval = FALSE}
#timecheck <- Torn50_19.sfdf %>%
#  filter(date == Torn50_18.sfdf$date && (Torn50_19.sfdf$time %in% Torn50_18.sfdf$time))
```

In the 2020 data, we can also use the start lat and lon to create an `sp` object. We then can convert it to `sf` data frame and set the coordinate reference system (crs) to EPSG 4326 [WGS 84]. However, we need to adjust the column headers of the 2020 tornado files to match those of the 1950 to 2019 data frame. 

https://www.ncdc.noaa.gov/stormevents/choosedates.jsp?statefips=-999%2CALL
https://www.ncdc.noaa.gov/stormevents/ftp.jsp
Read the 2020 tornado data into R.
```{r, eval = FALSE}
Torn2020.spdf <-read.csv(file = "2020_TornadoData.csv")
```

The column headers do not match the 1950 to 2019 data frame. Therefore, you MUST rename the column headers before you can combine the data frames. Change the column names using the `colnames` function. 
```{r, eval = FALSE}
cols <- c("eventid", "county", "city", "date", "originaltime", "eventtype", "mag_NA", "mag", "fat", "inj", "loss", "closs", "st", "timezone", "magtype", "epiid", "cztype", "stf", "WFO", "injind", "fatind", "source", "floodcause", "len", "wid", "brange", "bazimuth", "erange", "eazimuth", "elocation", "slat", "slon", "elat", "elon", "eventnar", "episodenar", "om")
colnames(Torn2020.spdf) <- cols
```

Convert to a spatial points data frame using the start latitude and longitude for each tornado. Next, convert to a simple features data frame with a set coordinate reference system to the WGS 84 (`EPSG: 4236`)
```{r, eval = FALSE}
sp::coordinates(Torn2020.spdf) <- ~ slon + slat
Torn2020.sfdf <- st_as_sf(Torn2020.spdf)
st_crs(Torn2020.sfdf) <- WGS84
```

Adjust the date and time columns. Add columns for day (dy), month (mo), year (yr), time(CST) 
```{r, eval = FALSE}
mydates <- as.Date(c(Torn2020.sfdf$date), format = "%m/%d/%Y")

Torn2020.sfdf <-  Torn2020.sfdf %>%
  mutate(yr = rep(2020, 1131),
         dy = day(as.Date(c(date), format = "%m/%d/%Y")),
         mo = month(as.Date(c(date), format = "%m/%d/%Y")),
         mag = as.integer(substr(mag, 3,3)))
```

Convert times to the CST time zone. In the originaltime column, it has values of CST-6, EST-5, MST-7, and PST-8. Therefore, we create a `for` loop to convert these times to CST which is consistent with `Torn50_19.sfdf`.
```{r, eval = FALSE}
time <- c()
date <- c()

Torn2020.sfdf$date <- as.Date(Torn2020.sfdf$date, format = "%m/%d/%Y")

for (i in 1:1131){
  if(Torn2020.sfdf$timezone[i] == "CST-6") { 
    time <- append(time,Torn2020.sfdf$originaltime[i])
    date <- append(date, as.Date(Torn2020.sfdf$date[i]))
    } else if(Torn2020.sfdf$timezone[i] == "EST-5") {
    o_time <- ifelse((Torn2020.sfdf$originaltime[i] <= 100), (Torn2020.sfdf$originaltime[i] +1200-100), Torn2020.sfdf$originaltime[i] - 100)
    newdate <- if(Torn2020.sfdf$originaltime[i] <= 100) {as.Date(Torn2020.sfdf$date[i], format = "%m/%d/%Y", origin = "0020/01/01")-1 } else { as.Date(Torn2020.sfdf$date[i], format = "%m/%d/%Y")
    }
    date <- append(date, newdate)
    time <- append(time, (o_time))  
    }   else if(Torn2020.sfdf$timezone[i] == "MST-7") {
    o_time <- ifelse((Torn2020.sfdf$originaltime[i] >= 2300), (Torn2020.sfdf$originaltime[i]  - 2300), Torn2020.sfdf$originaltime[i] +100)
    newdate <- if(Torn2020.sfdf$originaltime[i] >= 2300) {as.Date(Torn2020.sfdf$date[i], format = "%m/%d/%Y", origin = "0020/01/01")+1 } else { as.Date(Torn2020.sfdf$date[i], format = "%m/%d/%Y")
    }
    time <- append(time, Torn2020.sfdf$originaltime[i])
    date <- append(date, as.Date(Torn2020.sfdf$date[i])) 
    }    else if(Torn2020.sfdf$timezone[i] == "PST-8") {
          o_time <- ifelse((Torn2020.sfdf$originaltime[i] >= 2200), (Torn2020.sfdf$originaltime[i]  - 2200), Torn2020.sfdf$originaltime[i] +200)
    newdate <- if(Torn2020.sfdf$originaltime[i] >= 2200) {as.Date(Torn2020.sfdf$date[i], format = "%m/%d/%Y", origin = "0020/01/01")+1 } else { as.Date(Torn2020.sfdf$date[i], format = "%m/%d/%Y")
      }
    time <- append(time,(Torn2020.sfdf$originaltime[i]))
    date <- append(date, as.Date(Torn2020.sfdf$date[i]))
    } else ("NA")
}

time <- chron(times=time)
time <- format(strptime(substr(as.POSIXct(sprintf("%04.0f", time), format="%H%M"), 12, 16), '%H:%M'), '%I:%M:%S %p')
time <- format(strptime(time, "%I:%M:%S"), "%H:%M:%S")

x<-as.POSIXct(time,format="%H:%M:%S")
hour <- hour(x)
tz <- rep(3, 1131)

Torn2020.sfdf <- cbind(Torn2020.sfdf, time, hour, tz)
```

Determine the column names in the `Torn50_19.sfdf`. 
```{r, eval = FALSE}
colnames(Torn50_19.sfdf)
```

Determine the column names in the `Torn2020.sfdf`. 
```{r, eval = FALSE}
colnames(Torn2020.sfdf)
```

Filter the column names in the `Torn50_19.sfdf` and `Torn2020.sfdf`. You want both data frames to have the same columns.  
```{r, eval = FALSE}
filter_cols <- c("om","yr", "mo", "dy", "date", "time", "tz", "st", "stf", "mag","inj", "fat", "loss", "closs", "elat", "elon", "len", "wid", "geometry")

Torn50_19.sfdf <-  Torn50_19.sfdf %>%
  dplyr::select(filter_cols)

Torn2020.sfdf <-  Torn2020.sfdf %>%
  dplyr::select(filter_cols)
#stn sn, ns, sg, f1m f2, f3, fc were removed from the 1950:2019 data file. 
```

Combine the 2020 and 1950 to 2019 data frames.
```{r, eval = FALSE}
Torn.sfdf <- as.data.frame(rbind(Torn50_19.sfdf, Torn2020.sfdf))
```

Remove tornadoes in Hawaii, Alaska, and Puerto Rico and those occurring before 1994. That year marks the beginning of comprehensive WSR-88D radar. For missing EF ratings use the modification rules (if/else) defined here: https://www.spc.noaa.gov/wcm/OneTor_F-scale-modifications.pdf 
```{r, eval = FALSE}
All_Tornadoes <- Torn.sfdf %>%
  filter(yr >= 1994,
         !st %in% c("AK", "PR", "HI")) %>%
  mutate(mag = ifelse(mag == -9 & len <= 5, 0, mag),
         mag = ifelse(mag == -9 & len > 5, 1, mag))
```

Add a data/time column also add columns for path length, width, and area in metric units. Leave the time zone as native CDT. Create a convective day (6AM to 6AM) column taking hours 00:00:00 -> 05:59:59 and assigning it to the previous date (this associates the previous day's date to tornadoes occurring up to 6 hours after local midnight).
```{r, eval = FALSE}
All_Tornadoes <- All_Tornadoes %>%
  mutate(#dy = format(as.Date(date,format="%y/%m/%d"), "%d"), #This is now an included column in data
         DateTime = as.POSIXct(paste(yr, mo, dy, time), format = "%Y%m%d%H:%M:%S"),
         Hour = hour(DateTime),
         Year = year(DateTime),
         cDateTime = DateTime - as.difftime(6, unit = "hours"),
         cDate = as.Date(as_datetime(ifelse(Hour < 6, (DateTime - 86400), cDateTime), tz = Sys.timezone())),
         Length = len * 1609.34,
         Length = ifelse(Length == 0, min(Length[Length > 0]), Length), #takes care of zero length
         Width = wid * .9144,
         Width = ifelse(Width == 0, min(Width[Width > 0]), Width), #takes care of zero width
         Width = ifelse(Year >= 1995, Width * pi/4, Width), #takes care of change: avg to max
         cas = inj + fat,
         AreaPath = Length * Width,
         Ma = factor(month.abb[mo], levels = month.abb[1:12])) %>%
  sf::st_sf()
dim(All_Tornadoes)[1]
```

The geometry type is `POINT`. Each tornado is represented as a single point location geometry (start location). Add power dissipation per tornado.

Add power dissipation per tornado. Use the empirical model for tornado winds by EF rating taken from Table 3-1 of NRC 2007. Percent area by EF rating for each EF category. Threshold wind speeds (m/s) are a lower bound 3-sec gusts on the operational EF Scale (Table 2-1 of NRC2007). This is based on work by Fricker et al. (2017). The model is
$$
E = A_p \rho \sum_{j=0}^{J} w_j v_j^{3},
$$
where $A_p$ is the area of the path, $\rho$ is area density [1 kg/m^3]  $v_j$ is the midpoint wind speed for each rating, and $w_j$ is the corresponding fraction of path area by EF rating. With no upper bound on the EF5 wind speeds, the midpoint wind speed is set at 97 m~s$^{-1}$ (7.5 m~s$^{-1}$ above the threshold wind speed consistent with the EF4 midpoint speed relative to its threshold)
```{r, eval = FALSE}
perc <- c(1, 0, 0, 0, 0, 0, 
          .772, .228, 0, 0, 0, 0,
          .616, .268, .115, 0, 0, 0,
          .529, .271, .133, .067, 0, 0,
          .543, .238, .131, .056, .032, 0,
          .538, .223, .119, .07, .033, .017)
percM <- matrix(perc, ncol = 6, byrow = TRUE)
threshW <- c(29.06, 38.45, 49.62, 60.8, 74.21, 89.41)
midptW <- c(diff(threshW)/2 + threshW[-length(threshW)], threshW[length(threshW)] + 7.5)
ef <- All_Tornadoes$mag + 1
EW3 <- numeric()
for(i in 1:length(ef)) EW3[i] = midptW^3 %*% percM[ef[i], ]
All_Tornadoes <- All_Tornadoes %>%
  mutate(ED = EW3 * AreaPath)
``` 

Determine the distance between tornadoes in space and time. Use a projection, not lat/lon. See https://epsg.io/102004. Extract the coordinates of the start locations as a N by 2 matrix, where N is the number of tornadoes. Also extract the date-time as a vector of class `POSIXct`.
```{r, eval = FALSE}
All_Tornadoes <- st_transform(All_Tornadoes, crs = st_crs(US_LCC))
space <- st_coordinates(All_Tornadoes)
time <- All_Tornadoes$DateTime
```

Next compute pairwise Euclidean distances in space and, separately, in time using the `dist()` function. Divide the spatial distance by 15 so that the values are commensurate with the time 'distance' based on the assumption of 15 meters per second (~34 mph) for an average speed of tornado-generating storms. Compare: Distance from New York to Denver is 2.622 x 10^6 meters. There are 3.154 x 10^7 seconds in a year. This will capture the historic multiday tornado outbreaks. For analysis we want to consider each day in the multiday group separately. As the value of the divisor increases cluster areas get larger. Remove `ds` and `dt` to free memory. Distances are saved as an object of class `dist` containing a vector of length N * (N-1)/2, which is the number of unique point pairs.
```{r, eval = FALSE}
ds <- (dist(space) / 15)
dt <- dist(time)
dst <- ds + dt
rm(ds, dt)
```

Distances are saved as an object of class `dist` containing a vector of length N * (N-1)/2, which is the number of unique point pairs.

Next group the tornadoes based on the space-time distances. This is done with the `hclust()` (hierarchical cluster) function. Initially, each tornado is assigned to its own group and then the algorithm joins the two closest tornadoes determined by values in `dst`. The algorithm continues by joining tornadoes (and tornado groups) until there is a single large group.

The single linkage method (`method = "single"`) is related to the minimal spanning tree (MST) and adopts a 'friends of friends' grouping strategy. An edge-weighted graph is a graph where each edge has a weight (or cost). Here weights are space-time distances between tornadoes. A MST of an edge-weighted graph is a spanning tree whose weight (the sum of the weights of its edges) is no larger than the weight of any other spanning tree. A spanning tree of a graph on N vertices (tornado centroids) is a subset of N-1 edges that form a tree (Skiena 1990, p. 227).
 
The `cutree()` function is used to extract a group number for each tornado. Tornadoes in each group are close in space & time. Here the tree is cut at a height of 50000 space-time units. Making `h` smaller results in smaller groups (fewer tornadoes per group).
```{r, eval = FALSE}
stime <- proc.time()
tree <- hclust(dst, method = "single")
groupNumber <- as.integer(cutree(tree, h = 50000))
proc.time() - stime
```

Add the group number to each tornado. 
```{r, eval = FALSE}
All_Tornadoes$groupNumber <- groupNumber
```

Compute group-level statistics. 
```{r, eval = FALSE}
LargeGroups1994_2020  <- All_Tornadoes %>%
  group_by(groupNumber) %>%
  summarize(Year = first(Year),
            Month = first(mo),
            FirstDate = first(date),
            LastDate = last(date),
            Name = paste(FirstDate, "to", LastDate),
            FirstcDate = first(cDate),
            LastcDate = last(cDate),
            ncD = n_distinct(cDate),
            nT = n(),
            n0 = sum(mag == 0),
            n1 = sum(mag == 1),
            n2 = sum(mag == 2),
            n3 = sum(mag == 3),
            n4 = sum(mag == 4),
            n5 = sum(mag == 5),
            ATP = sum(ED),
            ATP_TW = paste(round(ATP/10^12), "TW"),
            maxEF = max(mag),
            nD = n_distinct(date),
            StartTime = first(DateTime),
            EndTime = last(DateTime),
            Duration = difftime(EndTime, StartTime, units = "secs"), 
            cas = sum(inj + fat)) %>% filter(nT >= 30)
```
There are 6878 Groups and 180 large groups.

Get the tornadoes that are in the 180 large groups. 
```{r}
LargeGroupTorns1994_2020 <- All_Tornadoes %>%
  filter(groupNumber %in% LargeGroups1994_2020$groupNumber)
```

########################################
## Extract Big Days from Large Groups ##
########################################

Filter individual tornadoes to remove those that are not part of a large group. Group by group number and convective dates. Remove days within big groups (group days) having fewer than 10 tornadoes.
```{r}
BigDaysLargeGroups1994_2020 <- All_Tornadoes %>%
  filter(groupNumber %in% LargeGroups1994_2020$groupNumber) %>%
  group_by(groupNumber, cDate) %>%
  summarize(nT = n(),
            n0 = sum(mag == 0),
            n1 = sum(mag == 1),
            n2 = sum(mag == 2),
            n3 = sum(mag == 3),
            n4 = sum(mag == 4),
            n5 = sum(mag == 5),
            ATP = sum(ED),
            maxATP = max(ED),
            avgATP = mean(ED),
            GroupDayCas = sum(cas),
            GroupDayFat = sum(fat),
            StartTime_CST = first(DateTime),
            EndTime_CST= last(DateTime),
            StartTime_UTC = StartTime_CST + 21600,
            EndTime_UTC = EndTime_CST + 21600,
            Duration = difftime(EndTime_CST, StartTime_CST, units = "secs")) %>%
  filter(nT >= 10) %>%
  mutate(Year = year(cDate),
         Mo = month(cDate),
         Month = format(cDate, "%m"), # this is needed to preserve the leading zeros
         Day = format(cDate, "%d"), 
         ATP_TW = ATP/10^12)                                                                                      
dim(BigDaysLargeGroups1994_2020)
```
There are 245 big days in large groups. These will be used for further analysis and modeling.


Get the tornadoes that are in the 180 large groups. 
```{r}
BigDayLargeGroupTorns1994_2020 <- All_Tornadoes %>%
  filter(groupNumber %in% BigDaysLargeGroups1994_2020$groupNumber)
```



What is the percentage of all big days (>= 10 tornadoes) that occur within a big group?
```{r}
TotalBigDays <- All_Tornadoes %>%
  group_by(groupNumber, cDate) %>%
  summarize(nT = n()) %>%
  filter(nT >= 10)

dim(BigDaysLargeGroups1994_2020)[1]/dim(TotalBigDays)[1] * 100
```
29.5% of all big days (>= 10 tornadoes) occur within a big group/outbreak (>= 30 tornadoes)



########STOPHERE 

Create a unique ID for each big day and each tornado. Extract the tornadoes associated with each big day using the unique ID. 
```{r}
BigDayTornadoes <- All_Tornadoes %>%
   mutate(ID = paste0(gsub("-", "", cDate), groupNumber))
BigDays.sfdfT <- BigDays.sfdfT %>%
   mutate(ID = paste0(gsub("-", "", cDate), groupNumber))

BigDayTornadoes <- BigDayTornadoes %>%
  filter(ID %in% BigDays.sfdfT$ID)

sum(BigDays.sfdfT$nT)
```
Rename: 
```{r}
BigDayLargeGroups1994_2020 <- BigDays.sfdfT
LargeGroups1994_2020 <- Groups.sfdfT
BigDayLargeGroupsTorns1994_2020 <- BigDayTornadoes
LargeGroupTorns1994_2020 <-GroupTornadoes
```

```{r}
load("BigDays.RData")

BigDays1994_2020 <- BigDays.sfdfT
BigDayTorns1994_2020 <- BigDayTornadoes
```


```{r}
#save("BigDayLargeGroups1994_2020", "BigDayLargeGroupsTorns1994_2020", "LargeGroups1994_2020", "LargeGroupTorns1994_2020", "BigDays1994_2020", "BigDayTorns1994_2020", file = "BigDays1994_2020.RData" )

load("BigDays1994_2020.RData")
```

```{r}
MultidayGroups <- LargeGroups1994_2020 %>%
  group_by(ncD) %>%
  summarize(TotGroups = n(),
            TotTorns = sum(nT))
```

```{r}
(sum(MultidayGroups$TotGroups) - MultidayGroups$TotGroups[1])/dim(LargeGroups1994_2020)[1]
```

```{r}
BigDaysLargeGroups1994_2020 %>% 
  arrange(desc(nT)) %>%
  head(10) %>%
  dplyr::select(cDate, nT, GroupDayCas)
``` 

```{r}
max(BigDaysLargeGroups1994_2020$nT)

mean(BigDaysLargeGroups1994_2020$nT)
```

```{r}
sum(BigDaysLargeGroups1994_2020$nT <= 22) / dim(BigDaysLargeGroups1994_2020)[1]
```

**Map of the longest tornado outbreak. Tornado points colored by cDate. **

```{r, eval = FALSE}
longestgroup <- LargeGroups1994_2020 %>%
  filter(groupNumber == 3075)

longestgroup <- st_convex_hull(longestgroup)

#longestdays <- BigDays.sfdfT %>%
 # filter(groupNumber == 3075)

longestdaytorns <- LargeGroupTorns1994_2020 %>%
  filter(groupNumber == 3075)
```

```{r, eval = FALSE}
sts <- state.name[!state.name %in% c("Alaska", "Hawaii")]
stateBorders <- us_states(states = sts)

longestdaytorns <- longestdaytorns %>%
  mutate(ID = as.factor(gsub("-", "", cDate)))

longestdaytorns$ID <- factor(longestdaytorns$ID, levels = rev(levels(longestdaytorns$ID)))
```

```{r}
tm_shape(stateBorders) + 
  tm_borders(col = "gray70") +
  tm_layout(legend.bg.color = "white", legend.text.size = .75) +
#tm_shape(counties.sf) +
#  tm_borders(col = "gray40", alpha = .3) +
tm_shape(longestgroup, merc, is.master = TRUE) + 
  tm_borders(col = "gray15", alpha = 1, lwd = 5) +
  tm_scale_bar(width = .3, size = 0.9, lwd = 2, color.dark = "gray70") +
  tm_compass(size = 3, lwd = 2, fontsize = 1, color.dark = "gray70") + 
    tm_format("World", legend.position = c("left", "top"),
                    attr.position = c("left", "top"),
                   legend.frame = FALSE,
                   #title = "Longest Group of Tornadoes",
                   #title.size = 1.3,
                   #title.position = c("left", "TOP"),
                   inner.margins = c(.05, .2, .05, .2)) + #.15S, .15W, .1,N .2 E
  tm_layout(legend.bg.color = "white", legend.text.size = .5) +
tm_shape(longestdaytorns) +
  tm_symbols(size = 4, alpha = 0.8, col = "ID", n = 5, palette = "seq", title.col = "September", labels = c("8th", "7th", "6th", "5th", "4th"), border.alpha = 0) + 
  tm_layout(legend.title.size = 1.1,
            legend.position = c("right", "bottom"), 
            legend.stack = "horizontal",
            legend.frame = FALSE, 
            legend.text.size = 1, legend.width = -0.3, aes.palette = list(seq = "-Greys"))
```
`Figure: A cluster of tornadoes in 2004 that occurred between September 4th and 8th. Each circle is a tornado genesis location colored by the day of occurrence. The black line is the minimum convex polygon surrounding all the genesis locations (convex hull)`  #CORRECT